{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/matej/prace/ferda/ferda_regtrack'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matej/prace/ferda/ferda_regtrack\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from core.project.project import Project\n",
    "from sys import maxsize\n",
    "import numpy as np\n",
    "import time\n",
    "from utils.gt.gt import GT\n",
    "from utils.gt.gt_project import GtProjectMixin\n",
    "import tqdm\n",
    "from core import global_cardinality_classifier as g_cardinality_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading cardinality classifier:  80%|████████  | 4/5 [00:00<00:00, 20.19it/s]\n",
      "ChunkManager rebuilding interval tree:   0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "loading project: 100%|██████████| 5/5 [00:00<00:00, 16.72it/s]\n"
     ]
    }
   ],
   "source": [
    "p = Project('test/project/Sowbug3_cut_300_frames')\n",
    "gt_path = 'data/GT/Sowbug3_cut.txt'\n",
    "# p = Project('../projects/2_temp/Camera3-5min/190719_2239')\n",
    "# gt_path = 'data/GT/Camera3-5min.mp4.txt'\n",
    "\n",
    "# p = Project('../projects/2_temp/Cam1_clip/190802_1621/')\n",
    "# gt_path = 'data/GT/Cam1_clip.avi.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GtProject(GtProjectMixin, GT):\n",
    "    pass\n",
    "\n",
    "correct_labels = {}\n",
    "gt = GtProject(filename=gt_path)\n",
    "gt.set_project_offsets(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4c641eb9b642e99691ab4eb6425c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5928/5928 [00:05<00:00, 1027.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# construct mapping \"tracklet id -> number of objects\" from GT\n",
    "for tracklet in tqdm.tqdm_notebook(p.chm.tracklet_gen(), total=len(p.chm)):\n",
    "    id_set = gt.tracklet_id_set(tracklet, p)\n",
    "    if id_set is not None:\n",
    "        correct_labels[tracklet.id()] = len(id_set)\n",
    "    else:\n",
    "        correct_labels[tracklet.id()] = None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: 1,\n",
       " 4: 2,\n",
       " 5: 1,\n",
       " 346: 1,\n",
       " 347: 1,\n",
       " 502: 1,\n",
       " 503: 1,\n",
       " 693: 1,\n",
       " 694: 1,\n",
       " 737: 1,\n",
       " 738: 1,\n",
       " 747: 1,\n",
       " 749: 1,\n",
       " 798: 1,\n",
       " 799: 1,\n",
       " 827: 1,\n",
       " 828: 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#unique tracklets: 18, #collateral sets: 36\n"
     ]
    }
   ],
   "source": [
    "reload(g_cardinality_clf)\n",
    "collateral_sets = g_cardinality_clf.get_collateral_sets(p, max_frame=5000)\n",
    "tracklets = set([t for cs in collateral_sets for t in cs])\n",
    "print(\"#unique tracklets: {}, #collateral sets: {}\".format(len(tracklets), len(collateral_sets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predecessors t: 0.24388217926\n",
      "area median extraction time: 2.73370909691\n",
      "#animals 6, #tracklets: 719, #collateral sets: 1438, mean area: 925.0\n",
      "gamma: 2.0\n",
      "var registration t: 0.048476934433\n",
      "objective function: 92.4074997902\n",
      "constraints: 11.8778829575\n",
      "ILP construction tooks: 104.348696947s\n",
      "('Status:', 'Optimal')\n",
      "('Total Cost = ', 4346481.0)\n",
      "time: 2.42585492134s\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# compute cardinalities using ILP\n",
    "t = time.time()\n",
    "predecessors = g_cardinality_clf.generate_predecessor_map(tracklets, p)\n",
    "successors = g_cardinality_clf.generate_successor_map(tracklets, p)\n",
    "print(\"predecessors t: {}\".format(time.time() - t))\n",
    "\n",
    "num_animals = len(p.animals)\n",
    "t = time.time()\n",
    "areas = g_cardinality_clf.get_median_areas(tracklets, p)\n",
    "# TODO: medain_area should probably be median from all areas...\n",
    "median_area = np.median(areas.values())\n",
    "print(\"area median extraction time: {}\".format(time.time() - t))\n",
    "area_relaxation_coef = 0\n",
    "\n",
    "print(\"#animals {}, #tracklets: {}, #collateral sets: {}, mean area: {}\".format(num_animals, len(tracklets), len(collateral_sets), median_area))\n",
    "\n",
    "cardinalities = g_cardinality_clf.build_ilp_and_solve(tracklets, collateral_sets, predecessors, successors, num_animals, \n",
    "                                                      median_area, areas, \n",
    "                                                      print_ilp=False)  # area_relaxation_coef=area_relaxation_coef, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# ants3_tracklets = copy.copy(tracklets)\n",
    "# ants3_cardinalities = copy.copy(cardinalities)\n",
    "\n",
    "# sowbug3_tracklets = copy.copy(tracklets)\n",
    "# sowbug3_cardinalities = copy.copy(cardinalities)\n",
    "\n",
    "# zebrafish_tracklets = copy.copy(tracklets)\n",
    "# zebrafish_cardinalities = copy.copy(cardinalities)\n",
    "# correct_labels[7586] = 1\n",
    "# correct_labels[4368] = 1\n",
    "# correct_labels[4349] = 1\n",
    "# correct_labels[4438] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistake, id: 11201, correct cardinality: 0, estimated: 1\n",
      "COEF: 0, #mistakes: 1, len: 1\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# eval ILP results against tracklet cardinalities from GT\n",
    "tracklets_len = {t.id(): len(t) for t in tracklets}\n",
    "\n",
    "# for coef in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "for coef in [0]:\n",
    "#     cardinalities = g_cardinality_clf.build_ilp_and_solve(tracklets, collateral_sets, predecessors, successors, num_animals,\n",
    "#                                                           median_area, areas) # , area_relaxation_coef=coef)\n",
    "    num_mistakes = 0\n",
    "    \n",
    "    tracklets_len_sum = 0\n",
    "    \n",
    "    for id in correct_labels.keys():\n",
    "        if correct_labels[id] is not None and correct_labels[id] != cardinalities[id]:\n",
    "            print(\"mistake, id: {}, correct cardinality: {}, estimated: {}\".format(id, correct_labels[id], cardinalities[id]))\n",
    "            num_mistakes += 1\n",
    "            tracklets_len_sum += tracklets_len[id]\n",
    "            \n",
    "    print(\"COEF: {}, #mistakes: {}, len: {}\".format(coef, num_mistakes, tracklets_len_sum))\n",
    "    print(\"------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistake, id: 3214, correct cardinality: 2, estimated: single\n",
      "mistake, id: 8311, correct cardinality: 2, estimated: single\n",
      "mistake, id: 11201, correct cardinality: 0, estimated: single\n",
      "mistake, id: 11202, correct cardinality: 0, estimated: single\n",
      "mistake, id: 526, correct cardinality: 2, estimated: single\n",
      "mistake, id: 9396, correct cardinality: 2, estimated: single\n",
      "mistake, id: 11495, correct cardinality: 2, estimated: single\n",
      "mistake, id: 9526, correct cardinality: 2, estimated: single\n",
      "mistake, id: 1890, correct cardinality: 2, estimated: single\n",
      "mistake, id: 194, correct cardinality: 2, estimated: single\n",
      "mistake, id: 195, correct cardinality: 2, estimated: single\n",
      "mistake, id: 9853, correct cardinality: 2, estimated: single\n",
      "mistake, id: 8785, correct cardinality: 2, estimated: single\n",
      "mistake, id: 14398, correct cardinality: 2, estimated: single\n",
      "mistake, id: 105, correct cardinality: 2, estimated: single\n",
      "#mistakes: 15, len: 34\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# eval old cardinality classifier results stored in the project against tracklet cardinalities from GT\n",
    "num_mistakes = 0\n",
    "tracklets_len_sum = 0\n",
    "\n",
    "for t in tracklets:\n",
    "    try:\n",
    "        card = correct_labels[t.id()]\n",
    "        if card is None:\n",
    "            continue\n",
    "        if card == 0 and t.is_noise():\n",
    "            pass\n",
    "        elif card == 1 and t.is_single():\n",
    "            pass\n",
    "        elif card > 1 and t.is_multi():\n",
    "            pass\n",
    "        else:\n",
    "            print(\"mistake, id: {}, correct cardinality: {}, estimated: {}\".format(t.id(), correct_labels[t.id()], t.segmentation_class_str()))\n",
    "            num_mistakes += 1\n",
    "            tracklets_len_sum += len(t)\n",
    "    except:\n",
    "        print(t.id())\n",
    "    \n",
    "print(\"#mistakes: {}, len: {}\".format(num_mistakes, tracklets_len_sum))\n",
    "print(\"------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
